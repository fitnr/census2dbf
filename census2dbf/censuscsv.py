#!/usr/bin/env python
# encoding: utf-8

# Copyright Neil Freeman 2012-15
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.

# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import csv
import re
import datetime
import string
from collections import OrderedDict

NULLS = ['(X)', 'N']


def get_header(reader):
    '''extracts the header'''
    fieldnames = []
    row = next(reader)

    patt = re.compile(r'\w{7}US\d*')
    while not patt.match(row[0]):
        fieldnames.append(row)
        row = next(reader)

    return fieldnames


def suffix(name, strng):
    return name[:-1] + strng


def dedupe(names, compressor=None):
    '''Add suffixes to duplicate fieldnames'''
    setnames = set(names)

    compressor = compressor or names

    if len(setnames) < len(names):
        indices = dict((n, []) for n in setnames)
        suffixes = list(string.ascii_lowercase + string.digits)

        for i, name in enumerate(names):
            if compressor[i]:
                indices[name].append(i)

        for name, indexlist in indices.items():
            cnt = len(indexlist)
            if cnt > 1:
                newnames = [suffix(name, s) for s in suffixes if suffix(name, s) not in names]

                if len(newnames) < cnt:
                    raise RuntimeError("These field names are hard")

                for index, new in zip(indexlist, newnames):
                    names[index] = new

    return names


def rewritefieldnames(row, compressor=None):
    '''Extract the fieldnames from a Census CSV row'''
    if row[0] == '':
        row[0] = 'geoid'

    if len(row) > 1 and row[1] == '':
        row[1] = 'geoid2'

    if len(row) > 2 and row[2] == '':
        row[2] = 'geoname'

    # Replace illegal characters in fieldnames with underscore.
    # Clip each field to 10 characters.
    illegal = re.compile(r'([^\w]|_)')
    fieldnames = [illegal.sub('', x).lower()[:11] for x in row]

    return dedupe(fieldnames, compressor)


def fieldtype(name, value, nulls=None):
    '''Value should be a string read from the csv.
    Will return value in the (possibly) correct type.'''
    nulls = nulls or []

    if value in nulls:
        return None

    # Special exception for Census docs
    if name == 'geoid' or name == 'geoid2':
        return str

    try:
        floated = float(value)
        if floated == int(floated):
            return int
        else:
            return float
    except ValueError:
        return str


def picktype(types):
    '''Pick a type from an iterable of types'''
    if str in types:
        return str

    elif float in types:
        return float
    else:
        return int


def fieldspec(types=None, size=None):
    spec = {}

    if types:
        spec['type'] = picktype(types)

    if size is not None:
        spec['size'] = size

    return spec


def dbfspecs(fieldnames, reader, compressor=None):
    '''Inspect fields, determining length and type. Use latter to write DBF specs'''
    j = 0
    nulls = set(NULLS)
    compressor = compressor or fieldnames
    cols = [{} for _ in fieldnames]

    for j, row in enumerate(reader):
        for i, cell in enumerate(row):
            if compressor[i]:
                ftype = fieldtype(fieldnames[i], cell, nulls)
                cols[i]['types'] = cols[i].get('types', set()).union((ftype, ))
                cols[i]['size'] = max(cols[i].get('size', 0), len(cell))

    fields = [(name, fieldspec(**col)) for name, col in zip(fieldnames, cols)]

    # numrecords is 1-indexed
    return OrderedDict(fields), j + 1


def write_dd(input_file, output_file, include_cols=None):
    '''Write a data dictionary'''
    now = datetime.datetime.now()

    with open(input_file, 'r') as f:
        headers = get_header(csv.reader(f))

    datadict = zip(*headers)

    if include_cols:
        datadict = [(x, y) for x, y in datadict if x in include_cols]

    with open(output_file, 'w+') as g:
        msg = "Data Dictionary\nAutomatically extracted from the header of {0}\n{1}\n".format(
            input_file, now.strftime("%Y-%m-%d %H:%M"))

        g.write(msg)
        csv.writer(g, delimiter='\t').writerows(datadict)


def reset(reader, n):
    '''Reset a reader to the nth row.'''
    for _ in range(n):
        next(reader)


def parse(handle, cols=None):
    """open up the csv, decide what kind of format it is, and get the fields and data ready.
    input: file name
    output: fieldnames, lengths, types, data_dictionary"""
    reader = csv.reader(handle)

    # interested in the last row before things it turns into data
    # Tell is the position of the first data row
    header = get_header(reader)

    # Pointer is and end of first data row. Reset to start of data.
    handle.seek(0)
    reset(reader, len(header))

    if cols:
        cols = [i.lower() for i in cols]
        compressor = [n.lower() in cols for n in header[0]]
    else:
        compressor = None

    fields, numrecords = dbfspecs(header[0], reader, compressor=compressor)

    fields = OrderedDict(zip(rewritefieldnames(fields.keys(), compressor), fields.values()))

    # Reset to start of data again.
    handle.seek(0)
    reset(reader, len(header))

    return fields, numrecords, reader
